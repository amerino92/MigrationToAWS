{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Objective: \n",
    "Make a easy guideline for Python users who want to transfer its own database to the cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Tools:\n",
    "The tools necessary to make the migration are the following:\n",
    "    - Python 3.x\n",
    "    - Local Database (In this example, we will use PostgreSQL)\n",
    "    - An account in AWS (We will use S3, EC2 and RedShift)\n",
    "    - SQL Workbench/J (To make the queries in the clustered database in AWS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, there are different websites to make the installation of the tools:\n",
    "    - Python 3.x: https://www.python.org/downloads/\n",
    "    - AWS: https://aws.amazon.com/\n",
    "    - SQL Workbench/J: http://www.sql-workbench.net/manual/install.html\n",
    "Python libraries to develop this application:\n",
    "    - psycopg2: make the connection to my local database and my clustered database\n",
    "    - boto3: make the connection to AWS\n",
    "    - csv: use csv files\n",
    "    - time: suspend the execution of my program for few minutes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Steps:\n",
    "The website https://docs.aws.amazon.com/redshift/latest/gsg/getting-started.html will help us to make the migration. Below, I will make an example how to use those steps to make the transference.\n",
    "\n",
    "- Create IAM role:\n",
    "\n",
    "To create IAM role, please follow the instructions in this website: https://docs.aws.amazon.com/redshift/latest/gsg/rs-gsg-create-an-iam-role.html\n",
    "\n",
    "<img src=\"2018-10-10 (A).png\" alt=\"Alt text that describes the graphic\" title=\"A\" />\n",
    "\n",
    "Be sure the role created has as a policy AmazonS3ReadOnlyAccess:\n",
    "\n",
    "<img src=\"2018-10-10 (B).png\" alt=\"Alt text that describes the graphic\" title=\"B\" />\n",
    "\n",
    "- Create a cluster (Optional):\n",
    "\n",
    "To create a cluster in RedShift, follow the instructions in this website: https://docs.aws.amazon.com/redshift/latest/gsg/rs-gsg-launch-sample-cluster.html or run the application in Python. The app will create an example of a cluster with a default database (The function creating_cluster will do it). Below, there is a picture of our cluster.\n",
    "\n",
    "<img src=\"2018-10-10 (8).png\" alt=\"Alt text that describes the graphic\" title=\"8\" />\n",
    "\n",
    "- Configure VPC Security Group:\n",
    "\n",
    "The following website will authorize access to the cluster https://docs.aws.amazon.com/redshift/latest/gsg/rs-gsg-authorize-cluster-access.html . Make sure to configure the security group related to the cluster to authorize access: \n",
    "\n",
    "<img src=\"2018-10-10 (D).png\" alt=\"Alt text that describes the graphic\" title=\"D\" />\n",
    "\n",
    "- Connect to the cluster:\n",
    "\n",
    "Using SQL Workbench/J, we will make the connection to the cluster. First, we need the driver to connect SQL Workbench to AWS cluster. In this website, we will do it https://docs.aws.amazon.com/redshift/latest/mgmt/configure-jdbc-connection.html. Then, we have to configure Workbench using the following website https://docs.aws.amazon.com/redshift/latest/gsg/rs-gsg-connect-to-cluster.html. \n",
    "\n",
    "<img src=\"2018-10-10 (C).png\" alt=\"Alt text that describes the graphic\" title=\"C\" />\n",
    "\n",
    "- Create a bucket (Optional):\n",
    "\n",
    "To create a bucket in S3, follow the instructions in this website: https://docs.aws.amazon.com/AmazonS3/latest/user-guide/create-bucket.html or run the application in Python. The app will create an example of a bucket (The function creating_bucket will do it)\n",
    "\n",
    "<img src=\"2018-10-10 (6).png\" alt=\"Alt text that describes the graphic\" title=\"6\" />\n",
    "\n",
    "- Creating local files from our local database:\n",
    "\n",
    "We will do it using the application in Python. The following picture will show our database tables in PostgreSQL.\n",
    "\n",
    "<img src=\"2018-10-10 (3).png\" alt=\"Alt text that describes the graphic\" title=\"3\" />\n",
    "\n",
    "Running the application will convert to local files (the function convert_to_local_files will make this). Below, we will see a picture where converts to a local files (csv files)\n",
    "\n",
    "<img src=\"2018-10-10 (4).png\" alt=\"Alt text that describes the graphic\" title=\"4 />\n",
    "\n",
    "- Get access to AWS intance from local:\n",
    "\n",
    "This is a important step to achieve the access to Linux instance created in AWS. To do this, I prefer to use Putty to get access using fingerprints (you can consult this website to do it: https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/putty.html) or you are free to use another method (this website can help you with that https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/AccessingInstances.html)\n",
    "\n",
    "\n",
    "- Transfer local files to my bucket:\n",
    "\n",
    "Also, we will make use of our application. The function put_files_bucket will be in charge of doing this. Below, we will see some pictures which demonstrate how will look our bucket.\n",
    "\n",
    "<img src=\"2018-10-10 (7).png\" alt=\"Alt text that describes the graphic\" title=\"7\" />\n",
    "\n",
    "\n",
    "- Copy the files from my bucket to my clustered database:\n",
    "\n",
    "At the end, we will do this using the application as well. The function copy_from_s3_to_redshift will make this. Below, we will see a picture of our\n",
    "\n",
    "<img src=\"2018-10-10 (9).png\" alt=\"Alt text that describes the graphic\" title=\"9\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Conclusion:\n",
    "This steps allowed us to make the migration from a local database to the cluster, in this case AWS. This "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
